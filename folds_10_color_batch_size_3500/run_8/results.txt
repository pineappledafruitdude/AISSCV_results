net.optimized_memory = 0 
mini_batch = 1, batch = 1, time_steps = 1, train = 0 
Create CUDA-stream - 0 
Create cudnn-handle 0 
nms_kind: greedynms (1), beta = 0.600000 
nms_kind: greedynms (1), beta = 0.600000 
seen 64, trained: 224 K-images (3 Kilo-batches_64) 
calculation mAP (mean average precision)... 
Detection layer: 30 - type = 28 
Detection layer: 37 - type = 28 
detections_count = 605, unique_truth_count = 130 
rank = 0 of ranks = 605  rank = 100 of ranks = 605  rank = 200 of ranks = 605  rank = 300 of ranks = 605  rank = 400 of ranks = 605  rank = 500 of ranks = 605  rank = 600 of ranks = 605 class_id = 0, name = Mensa, ap = 75.06%   	 (TP = 10, FP = 4) 
class_id = 1, name = AKK, ap = 100.00%   	 (TP = 7, FP = 1) 
class_id = 2, name = Audimax, ap = 82.71%   	 (TP = 6, FP = 4) 
class_id = 3, name = Neue Bib, ap = 82.86%   	 (TP = 12, FP = 3) 
class_id = 4, name = Alte Bib, ap = 87.16%   	 (TP = 11, FP = 2) 
class_id = 5, name = Studierendenwerk, ap = 89.78%   	 (TP = 10, FP = 3) 
class_id = 6, name = Lernzentrum, ap = 100.00%   	 (TP = 7, FP = 5) 
class_id = 7, name = Mathebau, ap = 94.29%   	 (TP = 5, FP = 3) 
class_id = 8, name = Harber-Bosch-Reaktor, ap = 100.00%   	 (TP = 7, FP = 0) 
class_id = 9, name = Statue am Ehrenhof, ap = 85.71%   	 (TP = 6, FP = 0) 
class_id = 10, name = Heinrich-Hertz-Denkmal, ap = 98.48%   	 (TP = 10, FP = 1) 
class_id = 11, name = Kolben, ap = 63.10%   	 (TP = 4, FP = 3) 
class_id = 12, name = Waermeflasche, ap = 98.89%   	 (TP = 8, FP = 1) 
class_id = 13, name = Gruenderschmiede, ap = 96.67%   	 (TP = 4, FP = 1) 
for conf_thresh = 0.25, precision = 0.78, recall = 0.82, F1-score = 0.80 
for conf_thresh = 0.25, TP = 107, FP = 31, FN = 23, average IoU = 61.14 % 
IoU threshold = 50 %, used Area-Under-Curve for each unique Recall 
mean average precision (mAP@0.50) = 0.896219, or 89.62 % 
Set -points flag: 
`-points 101` for MS COCO 
`-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) 
`-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset 
